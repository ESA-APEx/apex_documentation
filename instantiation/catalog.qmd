---
title: STAC metadata catalog user guide
---

## Introduction

Requesting a dedicated STAC catalog for your project, allows you to keep track of input data, intermediate results, and versions of final products.

If you don't know what STAC is, we recommend that you familiarize yourself with the [basic concepts](https://stacspec.org/en) first.
Especially organizations responsible for data management or data processing in a project are very likely to have a need 
for STAC metadata. Also if FAIR data principles are important to you, you should consider using a catalog.

## What does APEx offer

You will get a dedicated STAC catalog, managed by the APEx team. This gives you full control over the metadata, without
having to worry about IT aspects such as security, backup or monitoring the service.
The catalog supports creating both private and public collections.

The data storage itself is _not_ included in the catalog. We recommend requesting object storage access with one of the
cloud providers in the NoR.

The catalog offers a REST HTTP API. It can be browsed visually using [STAC browser](https://radiantearth.github.io/stac-browser/#/?.language=en).

The metadata creation process is not automated. You will have to provide the metadata in a JSON format. The catalog gives
you full freedom in terms of STAC extension that you want to use.

## What software is used under the hood

The catalog is currently based on [stac-fastapi-elasticsearch-opensearch](https://github.com/stac-utils/stac-fastapi-elasticsearch-opensearch).
The database is a managed opensearch instance running on open telekom cloud.

The APEx team can roll out software upgrades if needed, but cannot provide support for custom software development.

## How to integrate the catalog in your project architecture

The role of the STAC catalog, is in essence to facilitate data discovery and exchange between different components in your
project. By the use of a shared metadata language, components can be decoupled and still work together. It allows different
project partners also to work together, even if they use different software stacks.

We list some common cases below. 

### Data set viewing

Data viewing is one of the most basic use cases. Most viewer implementations traditionally require to ingest data in a viewer
specific database. However, when metadata is sufficiently rich, and the viewer understands STAC, it can directly query the
STAC catalog, as long as it's sufficiently responsive for the low latency requirements of the viewer.

### Data processing

In the most basic case, a processing component simply stores final products in the catalog. Sufficiently advanced processing
systems will immediately generate STAC metadata, and may even allow writing into the catalog API directly. They also record 
data provenance, which is a key aspect of FAIR data principles.

In a more advanced case, the processing workflow requires storing intermediate products, or preprocessed ancillary data sets.
Also then, the STAC catalog can be used to keep track of these data sets. By doing so, the processing component can simply read
required inputs from STAC, and store (intermediate) results back into the catalog.

### Machine learning datasets

A more advanced but increasingly common use case is to use a catalog to track reference data sets, as well as training patches 
in a STAC catalog. Here we again have a pattern where various components like the EO processing system, model training scripts and
reference data management system all work together around a central metadata store.


## Examples

The 'Guides' section has a number of concrete Jupyter notebooks showing how you can interact with the catalog API.